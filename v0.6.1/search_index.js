var documenterSearchIndex = {"docs":
[{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"EditURL = \"https://github.com/devmotion/CalibrationErrors.jl/blob/main/examples/distribution/script.jl\"","category":"page"},{"location":"examples/distribution/#Distribution-of-calibration-error-estimates","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"(Image: )","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"You are seeing the HTML output generated by Documenter.jl and Literate.jl from the Julia source file. The corresponding notebook can be viewed in nbviewer.","category":"page"},{"location":"examples/distribution/#Packages","page":"Distribution of calibration error estimates","title":"Packages","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"using CairoMakie\nusing CalibrationErrors\nusing Distributions\nusing StatsBase\n\nusing LinearAlgebra\nusing Random\nusing Statistics\n\nCairoMakie.activate!(; type=\"svg\")","category":"page"},{"location":"examples/distribution/#Introduction","page":"Distribution of calibration error estimates","title":"Introduction","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"This example is taken from the publication \"Calibration tests in multi-class classification: A unifying framework\" by Widmann, Lindsten, and Zachariah (2019).","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"We estimate calibration errors of the model","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"beginaligned\n   g(X) sim mathrmDir(alpha)\n   Z sim mathrmBer(pi)\n   Y  g(X) = gamma Z = 1 sim mathrmCategorical(beta)\n   Y  g(X) = gamma Z = 0 sim mathrmCategorical(gamma)\nendaligned","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"where alpha in mathbbR_0^m determines the distribution of predictions g(X), pi  0 determines the degree of miscalibration, and beta defines a fixed categorical distribution.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"Here we consider only the choices alpha = (01 ldots 01), mimicking a distribution after training that is pushed towards the edges of the probability simplex, and beta = (1 0 ldots 0).","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"In our experiments we sample 250 predictions from the Dirichlet distribution textrmDir(alpha), and then we generate corresponding labels according to the model stated above, for different choices of pi and number of classes m.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"We evaluate the standard estimators of expected calibration error (ECE) based on a uniform binning scheme and a data-dependent binning scheme, and the biased estimator of the squared kernel calibration error (SKCE), the quadratic unbiased estimator of the SKCE, and the linear unbiased estimator of the SKCE for a specific choice of matrix-valued kernels.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"The sampling procedure and the evaluation are repeated 100 times, to obtain a sample of 100 estimates for each considered setting of pi and m.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"For our choice of alpha and beta, the analytical ECE with respect to the total variation distance _mathrmTV is","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"mathrmECE_mathrmTV = fracpi(m-1)m","category":"page"},{"location":"examples/distribution/#Estimates","page":"Distribution of calibration error estimates","title":"Estimates","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"function estimates(estimator, π::Real, m::Int)\n    # cache array for predictions, modified predictions, and labels\n    predictions = [Vector{Float64}(undef, m) for _ in 1:250]\n    targets = Vector{Int}(undef, 250)\n    data = (predictions, targets)\n\n    # define sampler of predictions\n    sampler_predictions = sampler(Dirichlet(m, 0.1))\n\n    # initialize estimates\n    estimates = Vector{Float64}(undef, 100)\n\n    # for each run\n    @inbounds for i in eachindex(estimates)\n        # sample predictions\n        rand!.((sampler_predictions,), predictions)\n\n        # sample targets\n        for (j, p) in enumerate(predictions)\n            if rand() < π\n                targets[j] = 1\n            else\n                targets[j] = rand(Categorical(p))\n            end\n        end\n\n        # evaluate estimator\n        estimates[i] = estimator(data)(predictions, targets)\n    end\n\n    return estimates\nend;\nnothing #hide","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"We use a helper function to run the experiment for all desired parameter settings.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"struct EstimatesSet\n    m::Vector{Int}\n    π::Vector{Float64}\n    estimates::Matrix{Vector{Float64}}\nend\n\nfunction estimates(estimator)\n    # for all combinations of m and π\n    mvec = [2, 10, 100]\n    πvec = [0.0, 0.5, 1.0]\n    estimatesmat = estimates.((estimator,), πvec', mvec)\n\n    return EstimatesSet(mvec, πvec, estimatesmat)\nend;\nnothing #hide","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"As mentioned above, we can calculate the analytic expected calibration error. For the squared kernel calibration error, we take the mean of the estimates of the unbiased quadratic estimator as approximation of the true value.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"We provide simple histogram plots of our results. The mean value of the estimates is indicated by a solid vertical line and the analytic calibration error for the ECE is visualized as a dashed line.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"function plot_estimates(set::EstimatesSet; ece=false)\n    # create figure\n    f = Figure(; resolution=(1080, 960))\n\n    # add subplots\n    nrows, ncols = size(set.estimates)\n    for (j, π) in enumerate(set.π), (i, m) in enumerate(set.m)\n        # obtain data\n        estimates = set.estimates[i, j]\n\n        # create new axis\n        ax = Axis(f[i, j]; ticks=LinearTicks(4))\n        i < nrows && hidexdecorations!(ax; grid=false)\n        j > 1 && hideydecorations!(ax; grid=false)\n\n        # plot histogram of estimates\n        h = fit(Histogram, estimates)\n        barplot!(ax, h; strokecolor=:black, strokewidth=0.5)\n\n        # indicate mean of estimates\n        vlines!(ax, [mean(estimates)]; linewidth=2)\n\n        # indicate analytic calibration error for ECE\n        if ece\n            vlines!(ax, [π * (m - 1) / m]; linewidth=2, linestyle=:dash)\n        end\n    end\n\n    # add labels and link axes\n    for (j, π) in enumerate(set.π)\n        Box(f[1, j, Top()]; color=:gray90)\n        Label(f[1, j, Top()], \"π = $π\"; padding=(0, 0, 5, 5))\n        linkxaxes!(contents(f[:, j])...)\n    end\n    for (i, m) in enumerate(set.m)\n        Box(f[i, ncols, Right()]; color=:gray90)\n        Label(f[i, ncols, Right()], \"$m classes\"; rotation=-π / 2, padding=(5, 5, 0, 0))\n        linkyaxes!(contents(f[i, :])...)\n    end\n    Label(f[nrows, 1:ncols, Bottom()], \"calibration error estimate\"; padding=(0, 0, 0, 75))\n    Label(f[1:nrows, 1, Left()], \"# runs\"; rotation=π / 2, padding=(0, 75, 0, 0))\n\n    return f\nend;\nnothing #hide","category":"page"},{"location":"examples/distribution/#Kernel-choice","page":"Distribution of calibration error estimates","title":"Kernel choice","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"We use a tensor product kernel consisting of an exponential kernel k(mu mu) = exp(- gamma p - p) on the space of predicted categorical distributions and a white kernel k(y y) = delta(y - y) on the space of targets 1ldotsm. The total variation distance is chosen as the norm on the space of predictions, and the inverse lengthscale gamma is set according to the median heuristic.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"struct MedianHeuristicKernel\n    distances::Matrix{Float64}\n    cache::Vector{Float64}\nend\n\nfunction MedianHeuristicKernel(n::Int)\n    return MedianHeuristicKernel(\n        Matrix{Float64}(undef, n, n), Vector{Float64}(undef, (n * (n - 1)) ÷ 2)\n    )\nend\n\nfunction (f::MedianHeuristicKernel)((predictions, targets))\n    distances = f.distances\n    cache = f.cache\n\n    # compute lengthscale with median heuristic\n    pairwise!(distances, TotalVariation(), predictions)\n    k = 0\n    @inbounds for j in axes(distances, 2), i in 1:(j - 1)\n        cache[k += 1] = distances[i, j]\n    end\n    λ = median!(cache)\n\n    # create tensor product kernel\n    kernel_predictions = with_lengthscale(ExponentialKernel(; metric=TotalVariation()), λ)\n    kernel_targets = WhiteKernel()\n\n    return kernel_predictions ⊗ kernel_targets\nend\nnothing #hide","category":"page"},{"location":"examples/distribution/#Expected-calibration-error","page":"Distribution of calibration error estimates","title":"Expected calibration error","text":"","category":"section"},{"location":"examples/distribution/#Uniform-binning","page":"Distribution of calibration error estimates","title":"Uniform binning","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"We start by analyzing the expected calibration error (ECE). For our estimation we use 10 bins of uniform width in each dimension.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"Random.seed!(1234)\ndata = estimates(_ -> ECE(UniformBinning(10), TotalVariation()))\nplot_estimates(data; ece=true)","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"(Image: )","category":"page"},{"location":"examples/distribution/#Non-uniform-binning","page":"Distribution of calibration error estimates","title":"Non-uniform binning","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"We repeat our experiments with a different data-dependent binning scheme. This time the bins will be computed dynamically by splitting the predictions at the median of the classes with the highest variance, as long as the number of bins does not exceed a given threshold and the number of samples per bin is above a certain lower bound. In our experiments we do not impose any restriction on the number of bins but only stop splitting if the number of samples is less than 10.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"Random.seed!(1234)\ndata = estimates(_ -> ECE(MedianVarianceBinning(10), TotalVariation()))\nplot_estimates(data; ece=true)","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"(Image: )","category":"page"},{"location":"examples/distribution/#Unbiased-estimators-of-the-squared-kernel-calibration-error","page":"Distribution of calibration error estimates","title":"Unbiased estimators of the squared kernel calibration error","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"Random.seed!(1234)\ndata = estimates(SKCE ∘ MedianHeuristicKernel(250))\nplot_estimates(data)\n\nRandom.seed!(1234)\ndata = estimates() do predictions_targets\n    return SKCE(MedianHeuristicKernel(250)(predictions_targets); blocksize=2)\nend\nplot_estimates(data)","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"(Image: )","category":"page"},{"location":"examples/distribution/#Biased-estimator-of-the-squared-kernel-calibration-error","page":"Distribution of calibration error estimates","title":"Biased estimator of the squared kernel calibration error","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"Random.seed!(1234)\ndata = estimates() do predictions_targets\n    return SKCE(MedianHeuristicKernel(250)(predictions_targets); unbiased=false)\nend\nplot_estimates(data)","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"(Image: )","category":"page"},{"location":"examples/distribution/#Package-and-system-information","page":"Distribution of calibration error estimates","title":"Package and system information","text":"","category":"section"},{"location":"examples/distribution/#Package-version","page":"Distribution of calibration error estimates","title":"Package version","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"      Status `~/work/CalibrationErrors.jl/CalibrationErrors.jl/examples/distribution/Project.toml`\n  [13f3f980] CairoMakie v0.7.2\n  [33913031] CalibrationErrors v0.6.1\n  [31c24e10] Distributions v0.25.48\n  [2913bbd2] StatsBase v0.33.15","category":"page"},{"location":"examples/distribution/#Computer-information","page":"Distribution of calibration error estimates","title":"Computer information","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"Julia Version 1.7.2\nCommit bf53498635 (2022-02-06 15:21 UTC)\nPlatform Info:\n  OS: Linux (x86_64-pc-linux-gnu)\n  CPU: Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-12.0.1 (ORCJIT, skylake-avx512)\nEnvironment:\n  JULIA_DEBUG = Documenter","category":"page"},{"location":"examples/distribution/#Manifest","page":"Distribution of calibration error estimates","title":"Manifest","text":"","category":"section"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"To reproduce the project environment of this example you can download the full Manifest.toml.","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"","category":"page"},{"location":"examples/distribution/","page":"Distribution of calibration error estimates","title":"Distribution of calibration error estimates","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"EditURL = \"https://github.com/devmotion/CalibrationErrors.jl/blob/main/examples/classification/script.jl\"","category":"page"},{"location":"examples/classification/#Classification-of-penguin-species","page":"Classification of penguin species","title":"Classification of penguin species","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"(Image: )","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"You are seeing the HTML output generated by Documenter.jl and Literate.jl from the Julia source file. The corresponding notebook can be viewed in nbviewer.","category":"page"},{"location":"examples/classification/#Packages","page":"Classification of penguin species","title":"Packages","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"using AlgebraOfGraphics\nusing CairoMakie\nusing CalibrationErrors\nusing DataFrames\nusing Distributions\nusing MLJ\nusing MLJNaiveBayesInterface\nusing PalmerPenguins\n\nusing Random\n\n# Plotting settings\nset_aog_theme!()\nCairoMakie.activate!(; type=\"svg\")","category":"page"},{"location":"examples/classification/#Data","page":"Classification of penguin species","title":"Data","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"In this example we study the calibration of different models that classify three penguin species based on measurements of their bill and flipper lengths.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We use the Palmer penguins dataset to to train and validate the models.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"penguins = dropmissing(DataFrame(PalmerPenguins.load()))\n\npenguins_mapping =\n    data(penguins) * mapping(\n        :bill_length_mm => \"bill length (mm)\", :flipper_length_mm => \"flipper length (mm)\"\n    )\ndraw(penguins_mapping * mapping(; color=:species) * visual(; alpha=0.7))","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"(Image: )","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We split the data randomly into a training and validation dataset. The training dataset contains around 60% of the samples.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"Random.seed!(1234)\nn = nrow(penguins)\nk = floor(Int, 0.7 * n)\nRandom.seed!(100)\npenguins.train = shuffle!(vcat(trues(k), falses(n - k)))\n\n# Plot the training and validation data\ndataset = :train => renamer(true => \"training\", false => \"validation\") => \"Dataset\"\nplt = penguins_mapping * mapping(; color=:species, col=dataset) * visual(; alpha=0.7)\ndraw(plt; axis=(height=300,))","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"(Image: )","category":"page"},{"location":"examples/classification/#Fitting-normal-distributions","page":"Classification of penguin species","title":"Fitting normal distributions","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"For each species, we fit independent normal distributions to the observations of the bill and flipper length in the training data, using maximum likelihood estimation.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"y, X = unpack(\n    penguins,\n    ==(:species),\n    x -> x === :bill_length_mm || x === :flipper_length_mm;\n    :species => Multiclass,\n    :bill_length_mm => MLJ.Continuous,\n    :flipper_length_mm => MLJ.Continuous,\n)\nmodel = fit!(machine(GaussianNBClassifier(), X, y); rows=penguins.train);\nnothing #hide","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"[ Info: Training Machine{GaussianNBClassifier,…}.\n","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We plot the estimated normal distributions.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"# plot datasets\nfg = draw(plt; axis=(height=300,))\n\n# plot Gaussian distributions\nxgrid = range(extrema(penguins.bill_length_mm)...; length=100)\nygrid = range(extrema(penguins.flipper_length_mm)...; length=100)\nlet f = (x, y, dist) -> pdf(dist, [x, y])\n    for (class, color) in zip(classes(y), Makie.wong_colors())\n        pdfs = f.(xgrid, ygrid', Ref(model.fitresult.gaussians[class]))\n        contour!(fg.figure[1, 1], xgrid, ygrid, pdfs; color=color)\n        contour!(fg.figure[1, 2], xgrid, ygrid, pdfs; color=color)\n    end\nend\n\nfg","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"(Image: )","category":"page"},{"location":"examples/classification/#Naive-Bayes-classifier","page":"Classification of penguin species","title":"Naive Bayes classifier","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"Let us assume that the bill and flipper length are conditionally independent given the penguin species. Then Bayes' theorem implies that","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"beginaligned\nmathbbP(mathrmspecies  mathrmbill mathrmflipper)\n= fracmathbbP(mathrmspecies) mathbbP(mathrmbill mathrmflipper  mathrmspecies)mathbbP(mathrmbill mathrmflipper) \n= fracmathbbP(mathrmspecies) mathbbP(mathrmbill  mathrmspecies) mathbbP(mathrmflipper  mathrmspecies)mathbbP(mathrmbill mathrmflipper)\nendaligned","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"This predictive model is known as naive Bayes classifier.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"In the section above, we estimated mathbbP(mathrmspecies), mathbbP(mathrmbill  mathrmspecies), and mathbbP(mathrmflipper  mathrmspecies) for each penguin species from the training data. For the conditional distributions we used a Gaussian approximation.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"predictions = MLJ.predict(model)\ntrain_predict = predictions[penguins.train]\nval_predict = predictions[.!penguins.train]\n\n# Plot datasets\nfg = draw(plt; axis=(height=300,))\n\n# Plot predictions\npredictions_grid = reshape(\n    MLJ.predict(model, reduce(hcat, vcat.(xgrid, ygrid'))'), length(xgrid), length(ygrid)\n)\nfor (class, color) in zip(classes(y), Makie.wong_colors())\n    p = pdf.(predictions_grid, class)\n    contour!(fg.figure[1, 1], xgrid, ygrid, p; color=color)\n    contour!(fg.figure[1, 2], xgrid, ygrid, p; color=color)\nend\n\nfg","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"(Image: )","category":"page"},{"location":"examples/classification/#Evaluation","page":"Classification of penguin species","title":"Evaluation","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We evaluate the probabilistic predictions of the naive Bayes classifier that we just trained.","category":"page"},{"location":"examples/classification/#Log-likelihood","page":"Classification of penguin species","title":"Log-likelihood","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We compute the average log-likelihood of the validation data. It is equivalent to the negative cross-entropy.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"val_y = y[.!penguins.train]\n-mean(cross_entropy(val_predict, val_y))","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"-0.12188703745583586","category":"page"},{"location":"examples/classification/#Brier-score","page":"Classification of penguin species","title":"Brier score","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"The average log-likelihood is also equivalent to the logarithmic score. The Brier score is another strictly proper scoring rule that can be used for evaluating probabilistic predictions.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"mean(brier_score(val_predict, val_y))","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"-0.07385286949971775","category":"page"},{"location":"examples/classification/#Expected-calibration-error","page":"Classification of penguin species","title":"Expected calibration error","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"As all proper scoring rules, the logarithmic and the Brier score can be decomposed in three terms that quantify the sharpness and calibration of the predictive model and the irreducible uncertainty of the targets that is inherent to the prediction problem. The calibration term in this decomposition is the expected calibration error (ECE)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"mathbbE dbig(P_X mathrmlaw(Y  P_X)big)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"with respect to the score divergence d.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"Scoring rules, however, include also the sharpness and the uncertainty term. Thus models can trade off calibration for sharpness and therefore scoring rules are not suitable for specifically evaluating calibration of predictive models.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"The score divergence to the logarithmic and the Brier score are the Kullback-Leibler (KL) divergence","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"dbig(P_X mathrmlaw(Y  P_X)big) = sum_y mathbbP(Y = y  P_X)\nlogbig(mathbbP(Y = y  P_X)  P_X(y)big)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"and the squared Euclidean distance","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"dbig(P_X mathrmlaw(Y  P_X)big) = sum_y big(P_X - mathrmlaw(Y  P_X)big)^2(y)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"respectively. The KL divergence is defined only if mathrmlaw(Y  P_X) is absolutely continuous with respect to P_X, i.e., if P_X(y) = 0 implies mathbbP(Y = y  P_X) = 0.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We estimate the ECE by binning the probability simplex of predictions P_X and computing the weighted average of the distances between the mean prediction and the distribution of targets in each bin.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"One approach is to use bins of uniform size.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"ece = ECE(UniformBinning(10), (μ, y) -> kl_divergence(y, μ));\nnothing #hide","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We have to work with a numerical encoding of the true penguin species and a corresponding vector of predictions. We use RowVecs to indicate that the rows in the matrix of probabilities returned by pdf are the predictions. If we would provide predictions as columns of a matrix, we would have to use ColVecs.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"val_yint = map(MLJ.levelcode, val_y)\nval_probs = RowVecs(pdf(val_predict, MLJ.classes(y)));\nnothing #hide","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We compute the estimate on the validation data:","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"ece(val_probs, val_yint)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"0.04860861700674836","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"For the squared Euclidean distance we obtain:","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"ece = ECE(UniformBinning(10), SqEuclidean())\nece(val_probs, val_yint)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"0.02426469201343113","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"Alternatively, one can use a data-dependent binning scheme that tries to split the predictions in a way that minimizes the variance in each bin.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"With the KL divergence we get:","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"ece = ECE(MedianVarianceBinning(5), (μ, y) -> kl_divergence(y, μ))\nece(val_probs, val_yint)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"0.027874966150111966","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"For the squared Euclidean distance we obtain:","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"ece = ECE(MedianVarianceBinning(5), SqEuclidean())\nece(val_probs, val_yint)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"0.012238423729555838","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We see that the estimates (of the same theoretical quantity!) are highly dependent on the chosen binning scheme.","category":"page"},{"location":"examples/classification/#Kernel-calibration-error","page":"Classification of penguin species","title":"Kernel calibration error","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"As an alternative to the ECE, we estimate the kernel calibration error (KCE). We keep it simple here, and use the tensor product kernel","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"kbig((mu y) (mu y)big) = delta_yy expbigg(-fracmu - mu_2^22nu^2 bigg)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"with length scale nu  0 for predictions mumu and corresponding targets y y. For simplicity, we estimate length scale nu with the median heuristic.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"distances = pairwise(SqEuclidean(), RowVecs(pdf(train_predict, MLJ.classes(y))))\nν = sqrt(median(distances[i] for i in CartesianIndices(distances) if i[1] < i[2]))\nkernel = with_lengthscale(GaussianKernel(), ν) ⊗ WhiteKernel();\nnothing #hide","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"We obtain the following biased estimate of the squared KCE (SKCE):","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"skce = SKCE(kernel; unbiased=false)\nskce(val_probs, val_yint)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"0.0007888007181424232","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"Similar to the biased estimates of the ECE, the biased estimates of the SKCE are always non-negative. The unbiased estimates can be negative as well, in particular if the model is (close to being) calibrated:","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"skce = SKCE(kernel)\nskce(val_probs, val_yint)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"5.077982135882213e-5","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"When the datasets are large, the quadratic sample complexity of the standard biased and unbiased estimators of the SKCE can become prohibitive. In these cases, one can resort to an estimator that averages estimates of non-overlapping blocks of samples. This estimator allows to trade off computational cost for increased variance.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"Here we consider the extreme case of blocks with two samples, which yields an estimator with linear sample complexity:","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"skce = SKCE(kernel; blocksize=2)\nskce(val_probs, val_yint)","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"0.019033063524410525","category":"page"},{"location":"examples/classification/#Package-and-system-information","page":"Classification of penguin species","title":"Package and system information","text":"","category":"section"},{"location":"examples/classification/#Package-version","page":"Classification of penguin species","title":"Package version","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"      Status `~/work/CalibrationErrors.jl/CalibrationErrors.jl/examples/classification/Project.toml`\n  [cbdf2221] AlgebraOfGraphics v0.6.4\n  [13f3f980] CairoMakie v0.7.2\n  [33913031] CalibrationErrors v0.6.1\n  [a93c6f00] DataFrames v1.3.2\n  [31c24e10] Distributions v0.25.48\n  [add582a8] MLJ v0.17.1\n  [33e4bacb] MLJNaiveBayesInterface v0.1.5\n  [8b842266] PalmerPenguins v0.1.3","category":"page"},{"location":"examples/classification/#Computer-information","page":"Classification of penguin species","title":"Computer information","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"Julia Version 1.7.2\nCommit bf53498635 (2022-02-06 15:21 UTC)\nPlatform Info:\n  OS: Linux (x86_64-pc-linux-gnu)\n  CPU: Intel(R) Xeon(R) Platinum 8272CL CPU @ 2.60GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-12.0.1 (ORCJIT, skylake-avx512)\nEnvironment:\n  JULIA_DEBUG = Documenter","category":"page"},{"location":"examples/classification/#Manifest","page":"Classification of penguin species","title":"Manifest","text":"","category":"section"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"To reproduce the project environment of this example you can download the full Manifest.toml.","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"","category":"page"},{"location":"examples/classification/","page":"Classification of penguin species","title":"Classification of penguin species","text":"This page was generated using Literate.jl.","category":"page"},{"location":"kce/#kce","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"","category":"section"},{"location":"kce/#Definition","page":"Kernel calibration error (KCE)","title":"Definition","text":"","category":"section"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"The kernel calibration error (KCE) is another calibration error. It is based on real-valued kernels on the product space mathcalP times mathcalY of predictions and targets.","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"The KCE with respect to a real-valued kernel k colon (mathcalP times mathcalY) times (mathcalP times mathcalY) to mathbbR is defined[WLZ21] as","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"mathrmKCE_k = sup_f in mathcalB_k bigg mathbbE_YP_X f(P_X Y) - mathbbE_Z_XP_X f(P_X Z_X)bigg","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"where mathcalB_k is the unit ball in the reproducing kernel Hilbert space (RKHS) to k and Z_X is an artificial random variable on the target space mathcalY whose conditional law is given by","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"Z_X  P_X = mu sim mu","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"The RKHS to kernel k, and hence also the unit ball mathcalB_k, consists of real-valued functions of the form f colon mathcalP times mathcalY to mathbbR.","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"For classification models with m classes, there exists an equivalent formulation of the KCE based on matrix-valued kernel tildek colon mathcalP times mathcalP to mathbbR^m times m on the space mathcalP of predictions.[WLZ19] The definition above can be rewritten as","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"mathrmKCE_tildek = sup_f in mathcalB_tildek bigg mathbbE_P_X big(mathrmlaw(Y  P_X) - P_Xbig)^mathsfT f(P_X) bigg","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"where the matrix-valued kernel tildek is given by","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"tildek_ij(p q) = k((p i) (q j)) quad (ij=1ldotsm)","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"and mathcalB_tildek is the unit ball in the RKHS of tildek, consisting of vector-valued functions f colon mathcalP to mathbbR^m. However, this formulation applies only to classification models whereas the general definition above covers all probabilistic predictive models.","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"For a large class of kernels the KCE is zero if and only if the model is calibrated.[WLZ21] Moreover, the squared KCE (SKCE) can be formulated in terms of the kernel k as","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"beginaligned\nmathrmSKCE_k = mathrmKCE_k^2 = int k(u v)  big(mathrmlaw(P_X Y) - mathrmlaw(P_X Z_X)big)(u) big(mathrmlaw(P_X Y) - mathrmlaw(P_X Z_X)big)(v) \n= mathbbE h_kbig((P_X Y) (P_X Y)big)\nendaligned","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"where (XY) is an independent copy of (XY) and","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"beginaligned\nh_kbig((mu y) (mu y)big) = kbig((mu y) (mu y)big) - mathbbE_Z sim mu kbig((mu Z) (mu y)big) \n- mathbbE_Z sim mu kbig((mu y) (mu Z)big) + mathbbE_Z sim mu Z sim mu kbig((mu Z) (mu Z)big)\nendaligned","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"The KCE is actually a special case of calibration errors that are formulated as integral probability metrics of the form","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"sup_f in mathcalF big mathbbE_YP_X f(P_X Y) - mathbbE_Z_XP_X f(P_X Z_X)big","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"where mathcalF is a space of real-valued functions of the form f colon mathcalP times mathcalY to mathbbR.[WLZ21] For classification models, the ECE with respect to common distances such as the total variation distance or the squared Euclidean distance can be formulated in this way.[WLZ19]","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"The maximum mean calibration error (MMCE)[KSJ] can be viewed as a special case of the KCE, in which only the most-confident predictions are considered.[WLZ19]","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"[KSJ]: Kumar, A., Sarawagi, S., & Jain, U. (2018). Trainable calibration measures for neural networks from kernel mean embeddings. In Proceedings of the 35th International Conference on Machine Learning (pp. 2805-2814).","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"[WLZ19]: Widmann, D., Lindsten, F., & Zachariah, D. (2019). Calibration tests in multi-class classification: A unifying framework. In Advances in Neural Information Processing Systems 32 (NeurIPS 2019) (pp. 12257–12267).","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"[WLZ21]: Widmann, D., Lindsten, F., & Zachariah, D. (2021). Calibration tests beyond classification. To be presented at ICLR 2021.","category":"page"},{"location":"kce/#Estimator","page":"Kernel calibration error (KCE)","title":"Estimator","text":"","category":"section"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"For the SKCE biased and unbiased estimators exist. In CalibrationErrors.jl SKCE lets you construct unbiased and biased estimators with quadratic and sub-quadratic sample complexity.","category":"page"},{"location":"kce/","page":"Kernel calibration error (KCE)","title":"Kernel calibration error (KCE)","text":"SKCE","category":"page"},{"location":"kce/#CalibrationErrors.SKCE","page":"Kernel calibration error (KCE)","title":"CalibrationErrors.SKCE","text":"SKCE(k; unbiased::Bool=true, blocksize=identity)\n\nEstimator of the squared kernel calibration error (SKCE) with kernel k.\n\nKernel k on the product space of predictions and targets has to be a Kernel from the Julia package KernelFunctions.jl that can be evaluated for inputs that are tuples of predictions and targets.\n\nOne can choose an unbiased or a biased variant with unbiased=true or unbiased=false, respectively (see details below).\n\nThe SKCE is estimated as the average estimate of different blocks of samples. The number of samples per block is set by blocksize:\n\nIf blocksize is a function blocksize(n::Int), then the number of samples per block is set to blocksize(n) where n is the total number of samples.\nIf blocksize is an integer, then the number of samplers per block is set to blocksize, indepedent of the total number of samples.\n\nThe default setting blocksize=identity implies that a single block with all samples is used.\n\nThe number of samples per block must be at least 1 if unbiased=false and 2 if unbiased=true. Additionally, it must be at most the total number of samples. Note that the last block is neglected if it is incomplete (see details below).\n\nDetails\n\nThe unbiased estimator is not guaranteed to be non-negative whereas the biased estimator is always non-negative.\n\nThe sample complexity of the estimator is O(mn), where m is the block size and n is the total number of samples. In particular, with the default setting blocksize=identity the estimator has a quadratic sample complexity.\n\nLet (P_X_i Y_i)_i=1ldotsn be a data set of predictions and corresponding targets. The estimator with block size m is defined as\n\nbigglfloor fracnm biggrfloor^-1 sum_b=1^lfloor nm rfloor\nB_b^-1 sum_(i j) in B_b h_kbig((P_X_i Y_i) (P_X_j Y_j)big)\n\nwhere\n\nbeginaligned\nh_kbig((μ y) (μ y)big) =   kbig((μ y) (μ y)big)\n                                   - 𝔼_Z  μ kbig((μ Z) (μ y)big) \n                                  - 𝔼_Z  μ kbig((μ y) (μ Z)big)\n                                   + 𝔼_Z  μ Z  μ kbig((μ Z) (μ Z)big)\nendaligned\n\nand blocks B_b (b = 1 ldots lfloor nm rfloor) are defined as\n\nB_b = begincases\n(i j) (b - 1) m  i  j leq bm   text(unbiased) \n(i j) (b - 1) m  i j leq bm   text(biased)\nendcases\n\nReferences\n\nWidmann, D., Lindsten, F., & Zachariah, D. (2019). Calibration tests in multi-class classification: A unifying framework. In: Advances in Neural Information Processing Systems (NeurIPS 2019) (pp. 12257–12267).\n\nWidmann, D., Lindsten, F., & Zachariah, D. (2021). Calibration tests beyond classification.\n\n\n\n\n\n","category":"type"},{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"introduction/#Probabilistic-predictive-models","page":"Introduction","title":"Probabilistic predictive models","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"A probabilistic predictive model predicts a probability distribution over a set of targets for a given feature. By predicting a distribution, one can express the uncertainty in the prediction, which might be inherent to the prediction task (e.g., if the feature does not contain enough information to determine the target with absolute certainty) or caused by insufficient knowledge of the underlying relation between feature and target (e.g., if only a small number of observations of features and corresponding targets are available).[1]","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"In the classification example we study the Palmer penguins dataset with measurements of three different penguin species and consider the task of predictin the probability of a penguin species (target) given the bill and flipper length (feature). For this classification task there exist many different probabilistic predictive models. We denote the feature by X and the target by Y, and let P_X be the prediction of a specific model P for a feature X. Ideally, we would like that","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"P_X = mathrmlaw(Y  X) qquad textalmost surely","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"i.e., the model should predict the law of target Y given features X.[2] Of course, usually it is not possible to achieve this in practice.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"A very simple class of models are models that yield the same prediction for all features, i.e., they return the same probabilities for the penguin species regardless of the bill and flipper length. Clearly, more complicated models take into account also the features and might output different predictions for different features.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"In contrast to probabilistic predictive models, non-probabilistic predictive models predict a single target instead of a distribution over targets. In fact, such models can be viewed as a special class of probabilistic predictive models that output only Dirac distributions, i.e., that always predict 100% probability for one penguin species and 0% probability for all others.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Some other prediction models output a single target together with a confidence score between 0 and 1. Even these models can be reformulated as probabilistic predictive models, arguably in a slightly unconventional way: they correspond to a probabilistic model for a a binary classification problem whose feature space is extended with the predicted target and whose target is the predicted confidence score.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"[1]: It does not matter how the model is obtained. In particular, both Bayesian and frequentist approaches can be used.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"[2]: In classification problems, the law mathrmlaw(Y  X) can be identified with a vector in the probability simplex. Therefore often we just consider this equivalent formulation, both for the predictions P_X and the law mathrmlaw(Y  X).","category":"page"},{"location":"introduction/#Calibration","page":"Introduction","title":"Calibration","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The main motivation for using a probabilistic model is that it provides additional information about the uncertainty of the predictions, which is valuable for decision making. A classic example are weather forecasts that also report the \"probability of rain\" instead of only if it will rain or not.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Therefore it is not sufficient if the model predicts an arbitrary distribution. Instead the predictions should actually express the involved uncertainties \"correctly\". One desired property is that the predictions are consistent: if the forecasts predict an 80% probability of rain for an infinite sequence of days, then ideally on 80% of the days it rains.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"More generally, mathematically we would like","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"P_X = mathrmlaw(Y  P_X) quad textalmost surely","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"i.e., the predicted distribution of targets should be equal to the distribution of targets conditioned on the predicted distribution.[3]","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"This statistical property is called calibration. If it is satisfied, a model is calibrated.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Obviously, the ideal model P_X = mathrmlaw(Y  X) is calibrated. However, also the naive model P_X = mathrmlaw(Y) that always predicts the marginal distribution of Y independent of the features is calibrated.[4] In fact, any model of the form","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"P_X = mathrmlaw(Y  phi(X)) quad textalmost surely","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"where phi is some measurable function, is calibrated.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"[3]: The general formulation applies not only to classification but to any prediction task with arbitrary target spaces, including regression.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"[4]: In meteorology, this model is called the climatology.","category":"page"},{"location":"introduction/#Calibration-error","page":"Introduction","title":"Calibration error","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Calibration errors such as the expected calibration error and the kernel calibration error measure the calibration, or rather the degree of miscalibration, of probabilistic predictive models. They allow a more fine-tuned analysis of calibration and enable comparisons of calibration of different models. Intuitively, calibration measures quantify the deviation of P_X and mathrmlaw(Y  P_X), i.e., the left and right hand side in the calibration definition.","category":"page"},{"location":"introduction/#Estimation","page":"Introduction","title":"Estimation","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The calibration error of a model depends on the true conditional distribution of targets which is unknown in practice. Therefore calibration errors have to be estimated from a validation data set.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Various estimators of different calibration errors such as the expected calibration error and the kernel calibration error are implemented in CalibrationErrors.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"CalibrationErrors.CalibrationErrorEstimator","category":"page"},{"location":"introduction/#CalibrationErrors.CalibrationErrorEstimator","page":"Introduction","title":"CalibrationErrors.CalibrationErrorEstimator","text":"(estimator::CalibrationErrorEstimator)(predictions, targets)\n\nEstimate the calibration error of a model from the set of predictions and corresponding targets using the estimator.\n\n\n\n\n\n","category":"type"},{"location":"others/#Other-calibration-errors","page":"Other calibration errors","title":"Other calibration errors","text":"","category":"section"},{"location":"others/#Unnormalized-calibration-mean-embedding-(UCME)","page":"Other calibration errors","title":"Unnormalized calibration mean embedding (UCME)","text":"","category":"section"},{"location":"others/","page":"Other calibration errors","title":"Other calibration errors","text":"Instead of the formulation of the calibration error as an integral probability metric one can consider the unnormalized calibration mean embedding (UCME).","category":"page"},{"location":"others/","page":"Other calibration errors","title":"Other calibration errors","text":"Let mathcalP times mathcalY be the product space of predictions and targets. The UCME for a real-valued kernel k colon (mathcalP times mathcalY) times (mathcalP times mathcalY) to mathbbR and m test locations is defined[WLZ] as","category":"page"},{"location":"others/","page":"Other calibration errors","title":"Other calibration errors","text":"mathrmUCME_km^2 = m^-1 sum_i=1^m Big(mathbbE_YP_X kbig(T_i (P_X Y)big) - mathbbE_Z_XP_X kbig(T_i (P_X Z_X)big)Big)^2","category":"page"},{"location":"others/","page":"Other calibration errors","title":"Other calibration errors","text":"where test locations T_1 ldots T_m are i.i.d. random variables whose law is absolutely continuous with respect to the Lebesgue measure on mathcalP times mathcalY.","category":"page"},{"location":"others/","page":"Other calibration errors","title":"Other calibration errors","text":"The plug-in estimator of mathrmUCME_km^2 is available as UCME.","category":"page"},{"location":"others/","page":"Other calibration errors","title":"Other calibration errors","text":"UCME","category":"page"},{"location":"others/#CalibrationErrors.UCME","page":"Other calibration errors","title":"CalibrationErrors.UCME","text":"UCME(k, testpredictions, testtargets)\n\nEstimator of the unnormalized calibration mean embedding (UCME) with kernel k and sets of testpredictions and testtargets.\n\nKernel k on the product space of predictions and targets has to be a Kernel from the Julia package KernelFunctions.jl that can be evaluated for inputs that are tuples of predictions and targets.\n\nThe number of test predictions and test targets must be the same and at least one.\n\nDetails\n\nThe estimator is biased and guaranteed to be non-negative. Its sample complexity is O(mn), where m is the number of test locations and n is the total number of samples.\n\nLet (T_i)_i=1ldotsm be the set of test locations, i.e., test predictions and corresponding targets, and let (P_X_j Y_j)_j=1ldotsn be a data set of predictions and corresponding targets. The plug-in estimator of mathrmUCME_km^2 is defined as\n\nm^-1 sum_i=1^m bigg(n^-1 sum_j=1^n kbig(T_i (P_X_j Y_j)big)\n- mathbbE_Z sim P_X_j kbig(T_i (P_X_j Z)big)bigg)^2\n\nReferences\n\nWidmann, D., Lindsten, F., & Zachariah, D. (2021). Calibration tests beyond classification. To be presented at ICLR 2021.\n\n\n\n\n\n","category":"type"},{"location":"others/","page":"Other calibration errors","title":"Other calibration errors","text":"[WLZ]: Widmann, D., Lindsten, F., & Zachariah, D. (2021). Calibration tests beyond classification. To be presented at ICLR 2021.","category":"page"},{"location":"ece/#ece","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"","category":"section"},{"location":"ece/#Definition","page":"Expected calibration error (ECE)","title":"Definition","text":"","category":"section"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"A common calibration measure is the so-called expected calibration error (ECE). In its most general form, the ECE with respect to distance measure d(p p) is defined[WLZ21] as","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"mathrmECE_d = mathbbE dbig(P_X mathrmlaw(Y  P_X)big)","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"As implied by its name, the ECE is the expected distance between the left and right hand side of the calibration definition with respect to d.","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"Usually, the ECE is used to analyze classification models.[GPSW17][VWALRS19] In this case, P_X and mathrmlaw(Y  P_X) can be identified with vectors in the probability simplex and d can be chosen as a the cityblock distance, the total variation distance, or the squared Euclidean distance.","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"For other probabilistic predictive models such as regression models, one has to choose a more general distance measure d between probability distributions on the target space since the conditional distributions mathrmlaw(Y  P_X) can be arbitrarily complex in general.","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"[GPSW17]: Guo, C., et al. (2017). On calibration of modern neural networks. In Proceedings of the 34th International Conference on Machine Learning (pp. 1321-1330).","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"[VWALRS19]: Vaicenavicius, J., et al. (2019). Evaluating model calibration in classification. In Proceedings of Machine Learning Research (AISTATS 2019) (pp. 3459-3467).","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"[WLZ21]: Widmann, D., Lindsten, F., & Zachariah, D. (2021). Calibration tests beyond classification. To be presented at ICLR 2021.","category":"page"},{"location":"ece/#Estimators","page":"Expected calibration error (ECE)","title":"Estimators","text":"","category":"section"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"The main challenge in the estimation of the ECE is the estimation of the conditional distribution mathrmlaw(Y  P_X) from a finite data set of predictions and corresponding targets. Typically, predictions are binned and empirical estimates of the conditional distributions are calculated for each bin. You can construct such estimators with ECE.","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"ECE","category":"page"},{"location":"ece/#CalibrationErrors.ECE","page":"Expected calibration error (ECE)","title":"CalibrationErrors.ECE","text":"ECE(binning[, distance = TotalVariation()])\n\nEstimator of the expected calibration error (ECE) for a classification model with respect to the given distance function using the binning algorithm.\n\nFor classification models, the predictions P_X_i and targets Y_i are identified with vectors in the probability simplex. The estimator of the ECE is defined as\n\nfrac1B sum_i=1^B dbig(overlineP_i overlineY_ibig)\n\nwhere B is the number of non-empty bins, d is the distance function, and overlineP_i and overlineY_i are the average vector of the predictions and the average vector of targets in the ith bin. By default, the total variation distance is used.\n\nThe distance has to be a function of the form\n\ndistance(pbar::Vector{<:Real}, ybar::Vector{<:Real}).\n\nIn particular, distance measures of the package Distances.jl are supported.\n\n\n\n\n\n","category":"type"},{"location":"ece/#Binning-algorithms","page":"Expected calibration error (ECE)","title":"Binning algorithms","text":"","category":"section"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"Currently, two binning algorithms are supported. UniformBinning is a binning schemes with bins of fixed bins of uniform size whereas MedianVarianceBinning splits the validation data set of predictions and targets dynamically to reduce the variance of the predictions.","category":"page"},{"location":"ece/","page":"Expected calibration error (ECE)","title":"Expected calibration error (ECE)","text":"UniformBinning\nMedianVarianceBinning","category":"page"},{"location":"ece/#CalibrationErrors.UniformBinning","page":"Expected calibration error (ECE)","title":"CalibrationErrors.UniformBinning","text":"UniformBinning(nbins::Int)\n\nBinning scheme of the probability simplex with nbins bins of uniform width for each component.\n\n\n\n\n\n","category":"type"},{"location":"ece/#CalibrationErrors.MedianVarianceBinning","page":"Expected calibration error (ECE)","title":"CalibrationErrors.MedianVarianceBinning","text":"MedianVarianceBinning([minsize::Int = 10, maxbins::Int = typemax(Int)])\n\nDynamic binning scheme of the probability simplex with at most maxbins bins that each contain at least minsize samples.\n\nThe data set is split recursively as long as it is possible to split the bins while satisfying these conditions. In each step, the bin with the maximum variance of predicted probabilities for any component is selected and split at the median of the predicted probability of the component with the largest variance.\n\n\n\n\n\n","category":"type"},{"location":"#CalibrationErrors.jl","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"","category":"section"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"Estimation of calibration errors.","category":"page"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"A package for estimating calibration errors from data sets of predictions and targets.","category":"page"},{"location":"#Related-packages","page":"CalibrationErrors.jl","title":"Related packages","text":"","category":"section"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"CalibrationTests.jl implements statistical hypothesis tests of calibration.","category":"page"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"pycalibration is a Python interface for CalibrationErrors.jl and CalibrationTests.jl.","category":"page"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"rcalibration is an R interface for CalibrationErrors.jl and CalibrationTests.jl.","category":"page"},{"location":"#Talk-at-JuliaCon-2021","page":"CalibrationErrors.jl","title":"Talk at JuliaCon 2021","text":"","category":"section"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"<center>\n<iframe width=\"560\" style=\"height:315px\" src=\"https://www.youtube-nocookie.com/embed/PrLsXFvwzuA\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>","category":"page"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"The slides of the talk are available as Pluto notebook.","category":"page"},{"location":"#Citing","page":"CalibrationErrors.jl","title":"Citing","text":"","category":"section"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"If you use CalibrationErrors.jl as part of your research, teaching, or other activities, please consider citing the following publications:","category":"page"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"Widmann, D., Lindsten, F., & Zachariah, D. (2019). Calibration tests in multi-class classification: A unifying framework. In Advances in Neural Information Processing Systems 32 (NeurIPS 2019) (pp. 12257–12267).","category":"page"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"Widmann, D., Lindsten, F., & Zachariah, D. (2021). Calibration tests beyond classification. International Conference on Learning Representations (ICLR 2021).","category":"page"},{"location":"#Acknowledgements","page":"CalibrationErrors.jl","title":"Acknowledgements","text":"","category":"section"},{"location":"","page":"CalibrationErrors.jl","title":"CalibrationErrors.jl","text":"This work was financially supported by the Swedish Research Council via the projects Learning of Large-Scale Probabilistic Dynamical Models (contract number: 2016-04278), Counterfactual Prediction Methods for Heterogeneous Populations (contract number: 2018-05040), and Handling Uncertainty in Machine Learning Systems (contract number: 2020-04122), by the Swedish Foundation for Strategic Research via the project Probabilistic Modeling and Inference for Machine Learning (contract number: ICA16-0015), by the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation, and by ELLIIT.","category":"page"}]
}
